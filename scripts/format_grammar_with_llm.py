#!/usr/bin/env python3
"""
LLM-powered grammar documentation formatter.
Uses Claude API to intelligently reformat poorly formatted text extracts.
"""

import os
import re
import time
from pathlib import Path
from typing import Optional

import anthropic


# Formatting prompt for Claude
FORMATTING_PROMPT = """–¢—ã —ç–∫—Å–ø–µ—Ä—Ç –ø–æ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—é –∞–∫–∞–¥–µ–º–∏—á–µ—Å–∫–∏—Ö —Ç–µ–∫—Å—Ç–æ–≤. –¢–µ–±–µ –¥–∞–Ω –ø–ª–æ—Ö–æ –æ—Ç—Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ñ—Ä–∞–≥–º–µ–Ω—Ç –∏–∑ –≥—Ä–∞–º–º–∞—Ç–∏–∫–∏ –∫–∞–±–∞—Ä–¥–∏–Ω—Å–∫–æ–≥–æ —è–∑—ã–∫–∞.

–¢–í–û–Ø –ó–ê–î–ê–ß–ê:
1. –£–±—Ä–∞—Ç—å –∞—Ä—Ç–µ—Ñ–∞–∫—Ç—ã –∏–∑–≤–ª–µ—á–µ–Ω–∏—è:
   - –ù–æ–º–µ—Ä–∞ —Å—Ç—Ä–æ–∫ —Å–æ —Å—Ç—Ä–µ–ª–∫–∞–º–∏ (1‚Üí, 2‚Üí, 100‚Üí –∏ —Ç.–¥.)
   - –ù–æ–º–µ—Ä–∞ —Å—Ç—Ä–∞–Ω–∏—Ü, –≤—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã–µ –≤ —Ç–µ–∫—Å—Ç
   - –õ–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã –∏ —Ä–∞–∑—Ä—ã–≤—ã

2. –î–æ–±–∞–≤–∏—Ç—å —Å—Ç—Ä—É–∫—Ç—É—Ä—É Markdown:
   - –ó–∞–≥–æ–ª–æ–≤–∫–∏ —Ä–∞–∑–¥–µ–ª–æ–≤ (##, ###, ####)
   - –†–∞–∑–¥–µ–ª—ã —Ç–∏–ø–∞ "8. –ì–ª–∞–≥–æ–ª" ‚Üí ## 8. –ì–ª–∞–≥–æ–ª
   - –ü–æ–¥—Ä–∞–∑–¥–µ–ª—ã "8.1. –ü–æ–¥—Ä–∞–∑–¥–µ–ª" ‚Üí ### 8.1. –ü–æ–¥—Ä–∞–∑–¥–µ–ª

3. –§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞—Ç—å —Ç–∞–±–ª–∏—Ü—ã:
   - –û–±—Ä–∞–º–∏—Ç—å –≤ ```
   - –°–æ—Ö—Ä–∞–Ω–∏—Ç—å —Å—Ç—Ä—É–∫—Ç—É—Ä—É –∏ –≤—ã—Ä–∞–≤–Ω–∏–≤–∞–Ω–∏–µ –∫–∞–∫ –º–æ–∂–Ω–æ –ª—É—á—à–µ
   - –ï—Å–ª–∏ —Ç–∞–±–ª–∏—Ü–∞ —Å–ª–æ–º–∞–Ω–∞ - –ø–æ—Å—Ç–∞—Ä–∞–π—Å—è –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–∏—Ç—å

4. –°–æ—Ö—Ä–∞–Ω–∏—Ç—å —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã–µ —ç–ª–µ–º–µ–Ω—Ç—ã:
   - –ö–∞–±–∞—Ä–¥–∏–Ω—Å–∫–∏–µ —Å–∏–º–≤–æ–ª—ã (”Ä, I, —ä, —å –∏ –¥—Ä.) - –æ—Å—Ç–∞–≤—å –ë–ï–ó –∏–∑–º–µ–Ω–µ–Ω–∏–π
   - –ú–æ—Ä—Ñ–µ–º–Ω—ã–µ —Ä–∞–∑–±–æ—Ä—ã (–ø—Ä–µ—Ñ–∏–∫—Å+–∫–æ—Ä–µ–Ω—å+—Å—É—Ñ—Ñ–∏–∫—Å)
   - –í—Å–µ –ø—Ä–∏–º–µ—Ä—ã –Ω–∞ –∫–∞–±–∞—Ä–¥–∏–Ω—Å–∫–æ–º –∏ —Ä—É—Å—Å–∫–æ–º
   - –õ–∏–Ω–≥–≤–∏—Å—Ç–∏—á–µ—Å–∫–∏–µ —Ç–µ—Ä–º–∏–Ω—ã –∏ –æ–±–æ–∑–Ω–∞—á–µ–Ω–∏—è

5. –£–ª—É—á—à–∏—Ç—å —á–∏—Ç–∞–µ–º–æ—Å—Ç—å:
   - –î–æ–±–∞–≤–∏—Ç—å –ø—É—Å—Ç—ã–µ —Å—Ç—Ä–æ–∫–∏ –º–µ–∂–¥—É –∞–±–∑–∞—Ü–∞–º–∏
   - –í—ã–¥–µ–ª–∏—Ç—å –ø—Ä–∏–º–µ—Ä—ã –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
   - –°–ø–∏—Å–∫–∏ –æ—Ñ–æ—Ä–º–∏—Ç—å —á–µ—Ä–µ–∑ –¥–µ—Ñ–∏—Å—ã –∏–ª–∏ —Ü–∏—Ñ—Ä—ã

–í–ê–ñ–ù–û:
- –ù–ï –∏–∑–º–µ–Ω—è–π —Å–æ–¥–µ—Ä–∂–∞–Ω–∏–µ, —Ç–æ–ª—å–∫–æ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ
- –ù–ï –ø–µ—Ä–µ–≤–æ–¥–∏ –∏ –Ω–µ –∏—Å–ø—Ä–∞–≤–ª—è–π —è–∑—ã–∫
- –°–û–•–†–ê–ù–ò –≤—Å–µ –∫–∞–±–∞—Ä–¥–∏–Ω—Å–∫–∏–µ –ø—Ä–∏–º–µ—Ä—ã —Ç–æ—á–Ω–æ –∫–∞–∫ –µ—Å—Ç—å
- –ï—Å–ª–∏ —á—Ç–æ-—Ç–æ –Ω–µ–ø–æ–Ω—è—Ç–Ω–æ - –æ—Å—Ç–∞–≤—å –∫–∞–∫ –µ—Å—Ç—å, –Ω–µ –≤—ã–¥—É–º—ã–≤–∞–π

–í–µ—Ä–Ω–∏ –¢–û–õ–¨–ö–û –æ—Ç—Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç –≤ Markdown, –±–µ–∑ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤.
"""


def extract_metadata(filename: str) -> tuple[str, str]:
    """Extract chunk number and page range from filename."""
    match = re.search(r'chunk_(\d+)_pages_(\d+-\d+)', filename)
    if match:
        return match.group(1), match.group(2)
    return "", ""


def format_with_claude(
    content: str,
    client: anthropic.Anthropic,
    chunk_num: str,
    pages: str,
    max_retries: int = 3
) -> Optional[str]:
    """Format content using Claude API with retries."""

    for attempt in range(max_retries):
        try:
            message = client.messages.create(
                model="claude-sonnet-4-20250514",  # Using latest Sonnet
                max_tokens=16000,
                temperature=0,  # Deterministic for formatting
                messages=[
                    {
                        "role": "user",
                        "content": f"{FORMATTING_PROMPT}\n\n---\n\n–§–†–ê–ì–ú–ï–ù–¢ (Chunk {chunk_num}, Pages {pages}):\n\n{content}"
                    }
                ]
            )

            formatted_text = message.content[0].text

            # Add metadata header
            header = f"""# Chunk {chunk_num}: Pages {pages}

*Source: Kabardian-Circassian Grammar Reference*
*Formatted with Claude AI*

---

"""
            return header + formatted_text

        except anthropic.RateLimitError:
            wait_time = 2 ** attempt  # Exponential backoff
            print(f"    Rate limit hit, waiting {wait_time}s...")
            time.sleep(wait_time)

        except Exception as e:
            print(f"    Error (attempt {attempt + 1}/{max_retries}): {e}")
            if attempt < max_retries - 1:
                time.sleep(2)
            else:
                return None

    return None


def process_file(
    input_path: Path,
    output_path: Path,
    client: anthropic.Anthropic,
    dry_run: bool = False
) -> bool:
    """Process a single grammar file."""

    # Extract metadata
    chunk_num, pages = extract_metadata(input_path.name)

    # Read original content
    with open(input_path, 'r', encoding='utf-8') as f:
        content = f.read()

    # Check size
    size_kb = len(content.encode('utf-8')) / 1024
    print(f"  Chunk {chunk_num} (pages {pages}) - {size_kb:.1f} KB")

    if dry_run:
        print(f"    [DRY RUN] Would format and save to {output_path.name}")
        return True

    # Format with Claude
    formatted = format_with_claude(content, client, chunk_num, pages)

    if formatted:
        # Write formatted content
        with open(output_path, 'w', encoding='utf-8') as f:
            f.write(formatted)
        print(f"    ‚úì Saved to {output_path.name}")
        return True
    else:
        print(f"    ‚úó Failed to format")
        return False


def main():
    """Main function to process all grammar files."""

    # Check for API key
    api_key = os.environ.get("ANTHROPIC_API_KEY")
    if not api_key:
        print("‚ùå Error: ANTHROPIC_API_KEY environment variable not set")
        print("\nSet it with:")
        print("  export ANTHROPIC_API_KEY='your-api-key'")
        return

    # Initialize client
    client = anthropic.Anthropic(api_key=api_key)

    # Define paths
    grammar_dir = Path(__file__).parent.parent / "references" / "grammar"

    # Find all txt files in subdirectories
    txt_files = sorted(grammar_dir.glob("*/chunk_*.txt"))

    if not txt_files:
        print("No files found to process!")
        return

    print(f"üîç Found {len(txt_files)} files to process\n")

    # Ask for confirmation
    print("This will:")
    print(f"  - Process {len(txt_files)} files using Claude API")
    print(f"  - Estimated cost: ~${len(txt_files) * 0.05:.2f} (rough estimate)")
    print(f"  - Estimated time: ~{len(txt_files) * 5 / 60:.0f} minutes")
    print()

    response = input("Continue? [y/N/test]: ").strip().lower()

    if response == 'test':
        # Test mode - process first 3 files
        txt_files = txt_files[:3]
        print(f"\nüß™ TEST MODE: Processing first {len(txt_files)} files\n")
    elif response != 'y':
        print("Cancelled.")
        return

    # Process each file
    success_count = 0
    failed_files = []

    print("\n" + "="*60)
    print("Starting processing...")
    print("="*60 + "\n")

    for i, txt_file in enumerate(txt_files, 1):
        print(f"[{i}/{len(txt_files)}] {txt_file.parent.name}/{txt_file.name}")

        # Create output path (change .txt to .md)
        output_file = txt_file.with_suffix('.md')

        try:
            if process_file(txt_file, output_file, client):
                success_count += 1
            else:
                failed_files.append(txt_file.name)

            # Rate limiting: wait between requests
            if i < len(txt_files):
                time.sleep(1)  # 1 second between files

        except KeyboardInterrupt:
            print("\n\n‚ö†Ô∏è  Interrupted by user")
            break
        except Exception as e:
            print(f"    ‚úó Unexpected error: {e}")
            failed_files.append(txt_file.name)

    # Summary
    print("\n" + "="*60)
    print("SUMMARY")
    print("="*60)
    print(f"‚úì Successfully processed: {success_count}/{len(txt_files)}")

    if failed_files:
        print(f"‚úó Failed: {len(failed_files)}")
        print("\nFailed files:")
        for fname in failed_files:
            print(f"  - {fname}")

    print("\nüí° Next steps:")
    print("1. Review the generated .md files")
    print("2. Check a few files manually for quality")
    print("3. If satisfied, you can remove .txt files")
    print("4. Update README.md to reflect new format")


if __name__ == "__main__":
    main()
